{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ProcessingBig\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\",6) \\\n",
    "    .config(\"spark.sql.repl.eagereval.enable\", True) \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"200s\") \\\n",
    "    .config(\"spark.network.timeout\", \"300s\") \\\n",
    "    .config(\"spark.pyspark.python\", sys.executable) \\\n",
    "    .config(\"spark.pyspark.driver.python\", sys.executable) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set the current working directory\n",
    "os.chdir(\"C:\\\\Users\\\\migue\\\\OneDrive\\\\Documents\\\\GitHub\\\\BigData\")\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Provide path to gzipped JSON file\n",
    "gzipped_json_path = os.path.join(current_dir, \"Books.jsonl.gz\")\n",
    "\n",
    "# Read the file into a DataFrame\n",
    "df = spark.read.json(gzipped_json_path)\n",
    "\n",
    "# Drop the \"images\" column\n",
    "df = df.drop(\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, SQLTransformer\n",
    "from pyspark.ml import Pipeline\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\migue\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\migue\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download nltk data\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a UDF to lemmatize tokenized words\n",
    "def lemmatize_words(words):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "lemmatize_udf = udf(lemmatize_words, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stages of the pipeline\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "\n",
    "# Remove stopwords\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "\n",
    "# Apply lemmatization using SQLTransformer\n",
    "lemmatizer_transformer = SQLTransformer(\n",
    "    statement=\"SELECT *, lemmatize_udf(filtered) AS lemmatized FROM __THIS__\"\n",
    ")\n",
    "\n",
    "# HashingTF and IDF\n",
    "hashingTF = HashingTF(inputCol=\"lemmatized\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "    tokenizer,\n",
    "    remover,\n",
    "    lemmatizer_transformer,\n",
    "    hashingTF,\n",
    "    idf\n",
    "])\n",
    "\n",
    "\n",
    "# Register the UDF\n",
    "spark.udf.register(\"lemmatize_udf\", lemmatize_udf)\n",
    "\n",
    "# Fit the pipeline to the DataFrame\n",
    "model = pipeline.fit(df)\n",
    "\n",
    "# Transform the DataFrame\n",
    "df = model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql.functions import col, lit, when\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, LinearSVC, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1-Score: 0.5799\n",
      "Decision Tree F1-Score: 0.4303\n",
      "Random Forest F1-Score: 0.5639\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights\n",
    "class_counts = df.groupBy(\"rating\").count().collect()\n",
    "total_count = df.count()\n",
    "class_weights = {row[\"rating\"]: total_count / row[\"count\"] for row in class_counts}\n",
    "\n",
    "# Add a weight column based on class weights\n",
    "df = df.withColumn(\"weight\", when(col(\"rating\") == 1, class_weights[1])\n",
    "                              .when(col(\"rating\") == 2, class_weights[2])\n",
    "                              .when(col(\"rating\") == 3, class_weights[3])\n",
    "                              .when(col(\"rating\") == 4, class_weights[4])\n",
    "                              .when(col(\"rating\") == 5, class_weights[5]))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(trainingData, testData) = df.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Define the models with the weight column\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"rating\", weightCol=\"weight\")\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"rating\", weightCol=\"weight\")\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"rating\", weightCol=\"weight\")\n",
    "\n",
    "# Define evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Create parameter grid for each model with a small set of parameters (as will be applied to a large dataset and computational capacity is limited)\n",
    "lr_paramGrid = (ParamGridBuilder()\n",
    "                .addGrid(lr.regParam, [0.1, 0.01])\n",
    "                .build())\n",
    "\n",
    "dt_paramGrid = (ParamGridBuilder()\n",
    "                .addGrid(dt.maxDepth, [10, 20])\n",
    "                .build())\n",
    "\n",
    "rf_paramGrid = (ParamGridBuilder()\n",
    "                .addGrid(rf.numTrees, [15, 30])\n",
    "                .addGrid(rf.maxDepth, [5, 10])\n",
    "                .build())\n",
    "\n",
    "\n",
    "# Set up CrossValidator for each model\n",
    "lr_cv = CrossValidator(estimator=lr, estimatorParamMaps=lr_paramGrid, evaluator=evaluator, numFolds=3)\n",
    "dt_cv = CrossValidator(estimator=dt, estimatorParamMaps=dt_paramGrid, evaluator=evaluator, numFolds=3)\n",
    "rf_cv = CrossValidator(estimator=rf, estimatorParamMaps=rf_paramGrid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# Create pipelines\n",
    "lr_pipeline = Pipeline(stages=[lr_cv])\n",
    "dt_pipeline = Pipeline(stages=[dt_cv])\n",
    "rf_pipeline = Pipeline(stages=[rf_cv])\n",
    "\n",
    "# Fit the models using cross-validation\n",
    "lr_model = lr_pipeline.fit(trainingData)\n",
    "dt_model = dt_pipeline.fit(trainingData)\n",
    "rf_model = rf_pipeline.fit(trainingData)\n",
    "\n",
    "# Predict the test data\n",
    "lr_predictions = lr_model.transform(testData)\n",
    "dt_predictions = dt_model.transform(testData)\n",
    "rf_predictions = rf_model.transform(testData)\n",
    "\n",
    "# Evaluate the models\n",
    "lr_f1 = evaluator.evaluate(lr_predictions)\n",
    "dt_f1 = evaluator.evaluate(dt_predictions)\n",
    "rf_f1 = evaluator.evaluate(rf_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Logistic Regression F1-Score: {lr_f1:.4f}\")\n",
    "print(f\"Decision Tree F1-Score: {dt_f1:.4f}\")\n",
    "print(f\"Random Forest F1-Score: {rf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\migue\\AppData\\Local\\Temp\\ipykernel_17920\\180930354.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame({\"Model\": [\"Logistic Regression\"], \"Accuracy\": [lr_accuracy], \"Precision\": [lr_precision], \"Recall\": [lr_recall], \"F1 Score\": [lr_f1]})])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.534390</td>\n",
       "      <td>0.656600</td>\n",
       "      <td>0.534390</td>\n",
       "      <td>0.579931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.358803</td>\n",
       "      <td>0.615046</td>\n",
       "      <td>0.358803</td>\n",
       "      <td>0.430266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.528991</td>\n",
       "      <td>0.616412</td>\n",
       "      <td>0.528991</td>\n",
       "      <td>0.563894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Logistic Regression  0.534390   0.656600  0.534390  0.579931\n",
       "0        Decision Tree  0.358803   0.615046  0.358803  0.430266\n",
       "0        Random Forest  0.528991   0.616412  0.528991  0.563894"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define evaluators for other metrics\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "# Evaluate the models\n",
    "def evaluate_model(predictions):\n",
    "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "    precision = evaluator_precision.evaluate(predictions)\n",
    "    recall = evaluator_recall.evaluate(predictions)\n",
    "    f1 = evaluator.evaluate(predictions)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Create a summary table\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
    "\n",
    "# Logistic Regression results\n",
    "lr_accuracy, lr_precision, lr_recall, lr_f1 = evaluate_model(lr_predictions)\n",
    "results = pd.concat([results, pd.DataFrame({\"Model\": [\"Logistic Regression\"], \"Accuracy\": [lr_accuracy], \"Precision\": [lr_precision], \"Recall\": [lr_recall], \"F1 Score\": [lr_f1]})])\n",
    "\n",
    "# Decision Tree results\n",
    "dt_accuracy, dt_precision, dt_recall, dt_f1 = evaluate_model(dt_predictions)\n",
    "results = pd.concat([results, pd.DataFrame({\"Model\": [\"Decision Tree\"], \"Accuracy\": [dt_accuracy], \"Precision\": [dt_precision], \"Recall\": [dt_recall], \"F1 Score\": [dt_f1]})])\n",
    "\n",
    "# Random Forest results\n",
    "rf_accuracy, rf_precision, rf_recall, rf_f1 = evaluate_model(rf_predictions)\n",
    "results = pd.concat([results, pd.DataFrame({\"Model\": [\"Random Forest\"], \"Accuracy\": [rf_accuracy], \"Precision\": [rf_precision], \"Recall\": [rf_recall], \"F1 Score\": [rf_f1]})])\n",
    "\n",
    "# Print the summary table\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Logistic Regression Confusion Matrix: \n",
      "\n",
      "prediction   1.0  2.0  3.0   4.0   5.0  Total\n",
      "1.0          179   54   51    29    69    382\n",
      "2.0           84   57   70    53    55    319\n",
      "3.0          126   99  163   103   101    592\n",
      "4.0          174  120  208   396   428   1326\n",
      "5.0          570  326  420   827  3758   5901\n",
      "Total       1133  656  912  1408  4411   8520\n",
      "\n",
      " Decision Tree Confusion Matrix: \n",
      "\n",
      "prediction   1.0  2.0  3.0   4.0   5.0  Total\n",
      "1.0          229   30   41    31    51    382\n",
      "2.0          143   33   44    37    62    319\n",
      "3.0          229   47  107   102   107    592\n",
      "4.0          425   76  203   290   332   1326\n",
      "5.0         1954  329  484   736  2398   5901\n",
      "Total       2980  515  879  1196  2950   8520\n",
      "\n",
      " Random Forest Confusion Matrix: \n",
      "\n",
      "prediction   1.0  2.0  3.0   4.0   5.0  Total\n",
      "1.0          142   23   43    47   127    382\n",
      "2.0           84   33   55    54    93    319\n",
      "3.0          118   44  127   124   179    592\n",
      "4.0          153   70  173   385   545   1326\n",
      "5.0          605  207  429   840  3820   5901\n",
      "Total       1102  377  827  1450  4764   8520\n"
     ]
    }
   ],
   "source": [
    "def confusion_matrix(predictions):\n",
    "    # Convert Spark DataFrame to Pandas DataFrame for pivot\n",
    "    conf_matrix = predictions.groupBy(\"rating\", \"prediction\").count().toPandas()\n",
    "\n",
    "    # Pivot to get the confusion matrix format\n",
    "    conf_matrix_pivot = conf_matrix.pivot(index='rating', columns='prediction', values='count').fillna(0)\n",
    "\n",
    "    # Calculate row sums and column sums\n",
    "    conf_matrix_pivot['Total'] = conf_matrix_pivot.sum(axis=1)\n",
    "    total_col = conf_matrix_pivot.sum(axis=0)\n",
    "    total_col.name = 'Total'\n",
    "\n",
    "    # Concatenate the totals to the confusion matrix\n",
    "    conf_matrix_pivot = pd.concat([conf_matrix_pivot, total_col.to_frame().T])\n",
    "\n",
    "    return conf_matrix_pivot\n",
    "\n",
    "\n",
    "print(\"\\n Logistic Regression Confusion Matrix: \\n\")\n",
    "print(confusion_matrix(lr_predictions))\n",
    "\n",
    "print(\"\\n Decision Tree Confusion Matrix: \\n\")\n",
    "print(confusion_matrix(dt_predictions))\n",
    "\n",
    "print(\"\\n Random Forest Confusion Matrix: \\n\")\n",
    "print(confusion_matrix(rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Predictions\n",
      "Model predicted rating 5, actual rating 1: \n",
      "\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+----------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |rating|prediction|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+----------+\n",
      "|Nothing but a 2 time looser!!!!!!!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |1.0   |5.0       |\n",
      "|I couldn't take this book seriously for a C Programming class. I'm fairly well into my computer science program at school, but I still like to read my course books even if the class is more geared for beginners. The book identifies core concepts of programming, shows lots of examples, and then just moves on. I don't know who the target audience for is in this book. They don't really do a great job explaining the concepts for beginners, and the author must expect beginners' to learn by mindlessly writing code. I'm familiar with C, so I can just look up documentation online. I can't imagine what use an experienced or expert C programmer would have use for in this book. There are lot better free resources online to learn C either using video tutorials or documentation. I recommend Kernighan and Ritchie's(they are the developers of this language) C Programming Language 2nd Edition: [[ASIN:0131103628 C Programming Language 2nd Edition]]|1.0   |5.0       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "\n",
      "\n",
      " Model predicted rating 5, actual rating 5: \n",
      "\n",
      "+--------------------------------------------------------------------------------------------------------------------------------+------+----------+\n",
      "|text                                                                                                                            |rating|prediction|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------+------+----------+\n",
      "|My kid loves this series....He actually read the book in an hour !!!<br />It's fun, light  and they canreally relate to Nate....|5.0   |5.0       |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------+------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "\n",
      "\n",
      " Model predicted rating 1, actual rating 5: \n",
      "\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+----------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                            |rating|prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+----------+\n",
      "|Bought this for my wife to replace a similar one she had literally worn out.  She loves it because she can find answers that she couldn't locate in similar crossword dictionaries I bought her.  If you like crossword puzzles, this is the dictionary to buy.  The only downside is it's a soft cover, so it deterioriates over time with use.|5.0   |1.0       |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "\n",
      "\n",
      " Model predicted rating 1, actual rating 1: \n",
      "\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+----------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |rating|prediction|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+----------+\n",
      "|\"I read Dr. Weinbeg's book along with his \"\"Self Creation\"\" book.  I actually misread his books and titles, called him up and was his patient for nearly three silly years.<br /><br />During the course of treatment I had a unique once in a lifetime flood of dreams.  Many were detailed to Dr. Weinberg.  He knew nothing about the meanngs at all.  All I got was his feel-good silly techniques designed to solve porblems like stopping smoking.<br /><br />Fortunately I left his therapy which was when my therapy began.<br /><br />He is a very good writer, none of which has much to do with real psychology.  The entertainment value of his books is good.  The useful value is a big zero.  As entertainment high marks.  As a tool for growth, change or self awareness a BIG ZERO.  This is from one who knows from personal experience how hollow and silly are his ideas and techniques.\"|1.0   |1.0       |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_specific_predictions(predictions, model_name):\n",
    "    print(f\"{model_name} Predictions\")\n",
    "\n",
    "    # Case 1: Model predicted rating 5, actual rating 1\n",
    "    print(\"Model predicted rating 5, actual rating 1: \\n\")\n",
    "    predictions.filter((col(\"prediction\") == 5) & (col(\"rating\") == 1)).select(\"text\", \"rating\", \"prediction\").show(2, truncate=False)\n",
    "\n",
    "    # Case 2: Model predicted rating 5, actual rating 5\n",
    "    print(\"\\n\\n Model predicted rating 5, actual rating 5: \\n\")\n",
    "    predictions.filter((col(\"prediction\") == 5) & (col(\"rating\") == 5)).select(\"text\", \"rating\", \"prediction\").show(1, truncate=False)\n",
    "\n",
    "    # Case 3: Model predicted rating 1, actual rating 5\n",
    "    print(\"\\n\\n Model predicted rating 1, actual rating 5: \\n\")\n",
    "    predictions.filter((col(\"prediction\") == 1) & (col(\"rating\") == 5)).select(\"text\", \"rating\", \"prediction\").show(1, truncate=False)\n",
    "\n",
    "    # Case 4: Model predicted rating 1, actual rating 1\n",
    "    print(\"\\n\\n Model predicted rating 1, actual rating 1: \\n\")\n",
    "    predictions.filter((col(\"prediction\") == 1) & (col(\"rating\") == 1)).select(\"text\", \"rating\", \"prediction\").show(1, truncate=False)\n",
    "\n",
    "# Logistic Regression Predictions\n",
    "show_specific_predictions(lr_predictions, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Conclusions**\n",
    "\n",
    "**Most accurate model**: Overall the model that presents the best metrics is the logistic regression model.\n",
    "Tree-based models do not show the same performance and appear to deal worse with the unbalanced data aspect of the problem (confusion matrix).\n",
    "\n",
    "**Limitations**: The dimension of the data and limited processing capabilities do not allow for a more thorough search towards the best combination of parameters as cross-validation needs to be done with larger sets of data and parameter grids are limited to smaller search spaces.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
